# Welcome to Use-AI.rs!

At **Use-AI.rs**, we create an open-source AI framework in Rust.  
Our goal is to build a concurrent, locally hostable AI agent for practical application in production environments.
To reach that goal we are going to build on top of [Burn](https://burn.dev/) instead of building on top
of [rust-gpu](https://github.com/Rust-GPU/rust-gpu/).
Burn provides us with the necessary operational instruments to reach our goal of providing a practical AI Framework.
For production coding we will focus on implementing reinforcement learning (RL) algorithms like Q-Learning and deep
Q-Networks.
As well ensemble learning algorithm are planed. In the first Iteration we will use gradient based decision trees (GBDT).

[Here](https://github.com/Use-AIrs/use-ai.rs/discussions/1) a blog for current insights in the tought process.

## Layer 0: GPU

The first idea was to go with [rust-gpu](https://github.com/Rust-GPU/rust-gpu/) for the GPU layer. But since we
got [Burn](https://burn.dev/)
we can skip the whole gpu abstraction part and abstract from Burn. That gives us the possibility to concentrate on AI
modeling and live learning since
the deep learning part ist already done. For implementing live learning we may also need to work
with/on [CubeCL](https://github.com/tracel-ai/cubecl).

## Layer 1: Core

The main role of the **core** layer is to provide operations required to execute any given model or logic.  
To ensure parallel execution, we enforce strict control over the data types passed to our operation functions.
With Serde we want to give a input jsons to build our operations trough Burn and CubeCL.

### Data Stages

Data is organized into five standardized stages:

1. **RawData**: Initial unprocessed data.
2. **ModelData**: Data formatted for building models.
3. **ResultModel**: The final trained model.
4. **DataInput**: Input for the DataTargetBuilder.
5. **DataTarget**: Output generated by a trained model.

### Layer 1.0.0: Calculator

This component provides mathematical and logical operations, optimized for parallelization where possible.

- Smaller dimensions may perform better on the CPU.
- We maintain flexibility to map operations to either the GPU or CPU based on workload.

### Layer 1.1: Operator

#### 1.1.0: DataRawBuilder

Processes CSV files to create a `DataRaw` struct.

#### 1.1.1: DataRaw

Represents the normalized form of raw input data, making it suitable for training purposes.

#### 1.1.2: DataBuilder

Transforms a `DataRaw` instance into a `Data` structure tailored to the specific model being used.

#### 1.1.3: Data

Organizes data for training purposes, optimized for a specific model.

#### 1.1.4: Trainer

Processes a `Data` structure to produce a `DataResult`.

#### 1.1.5: DataResult

Represents the trained model.

#### 1.1.6: DataInputBuilder

Creates a `DataInput` instance from `DataRaw`, tailored to a specific model.

#### 1.1.7: DataTargetBuilder

Combines a `DataResult` with a `DataInput` to generate a `DataTarget`.

#### 1.1.8: DataTarget

Enables the generation of outputs based on a given input.

#### 1.1.9: Live (Future Feature Idea)

Plans to implement live learning capabilities in future iterations.

### Layer 2.0: Model

The **model** component maps any model that can be supported by the **core** layer's features.  
In the first iteration, we will define a JSON format to describe how core functions meet a model's requirements.

#### JSON Structure

The JSON must encompass operations related to:

- **DataBuilder** (Layer 1.1.2)
- **Trainer** (Layer 1.1.4)
- **DataInputBuilder** (Layer 1.1.6)
- **DataTargetBuilder** (Layer 1.1.7)

By defining these requirements, the framework supports multiple AI logic types and enables a clear logical composition
for each process stage.

### Layer 3.0: Staging

Each layer in the **core** serves as either:

- A **stage** for storing information, or
- A **stage** for processing information.

The staging tool helps users navigate through these stages based on the chosen or supported model as async API.
